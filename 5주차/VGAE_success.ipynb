{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv, VGAE\n",
    "\n",
    "device = 'cpu'\n",
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True, split_labels=True, add_negative_train_samples=False),\n",
    "])\n",
    "\n",
    "dataset = Planetoid('.', name='Cora', transform=transform)\n",
    "train_data, val_data, test_data = dataset[0]\n",
    "train_data, val_data, test_data = train_data.to(device), val_data.to(device), test_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, dim_in, hidden_dim = 32, dim_out = 16):\n",
    "        super().__init__()\n",
    "        self.fc1 = GCNConv(dim_in, hidden_dim)\n",
    "        self.fc_average = GCNConv(hidden_dim, dim_out)\n",
    "        self.fc_log_variance = GCNConv(hidden_dim, dim_out)\n",
    " \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.fc1(x, edge_index).relu()\n",
    "        return self.fc_average(x, edge_index), self.fc_log_variance(x, edge_index)\n",
    " \n",
    "model = VGAE(Encoder(dataset.num_features, 16)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 3.416130304336548\n",
      "Test AUC : 0.668675219368521 | Test AP : 0.6958206661143584\n",
      "Train loss : 1.3364050388336182\n",
      "Test AUC : 0.635670023656154 | Test AP : 0.670486426553272\n",
      "Train loss : 1.299009919166565\n",
      "Test AUC : 0.637009458860976 | Test AP : 0.6720657173192042\n",
      "Train loss : 1.1670433282852173\n",
      "Test AUC : 0.740761677750613 | Test AP : 0.7413474020737971\n",
      "Train loss : 1.0603376626968384\n",
      "Test AUC : 0.8202852420885107 | Test AP : 0.8246690433361138\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "    loss = model.recon_loss(z, train_data.pos_edge_label_index) + (1 / train_data.num_nodes) * model.kl_loss()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    return model.test(z, data.pos_edge_label_index, data.neg_edge_label_index)\n",
    "\n",
    "\n",
    "for epoch in range(201):\n",
    "    loss = train()\n",
    "    test_auc, test_ap = test(test_data)\n",
    "    if epoch % 50 == 0:\n",
    "        print('Train loss : {}'.format(loss))\n",
    "        print('Test AUC : {} | Test AP : {}'.format(test_auc, test_ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test AUC: 0.8688 | Test AP: 0.8601\n"
     ]
    }
   ],
   "source": [
    "test_auc, test_ap = test(val_data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "64899620a4720dc65f8590bd807a147b9e0b586abbcb5f41c4838230f5e89ff5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.16 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
